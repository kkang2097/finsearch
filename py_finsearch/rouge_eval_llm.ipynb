{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b47efab",
   "metadata": {},
   "source": [
    "# Automated evaluation of FinanceBench using ROUGE-SU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086248aa",
   "metadata": {},
   "source": [
    "Currently, there are not that many automated eval options with LLMs.\n",
    "\n",
    "\n",
    "**Insert more text here\n",
    "- Goals\n",
    "- Approach\n",
    "- Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef924f5",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We can use NLTK to remove stop words and remap the questions into a `List[str]` type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b7c1f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from functools import partial\n",
    "import rouge_metric\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "#Data processing\n",
    "df = pd.read_csv(\"financebench_sample_150.csv\")[[\"question\", \"answer\"]]\n",
    "stop_words = list(set(stopwords.words('english')))\n",
    "def preprocess(sequence: str):\n",
    "    returnVal = [w for w in word_tokenize(sequence) if not w.lower() in stop_words]\n",
    "    #returnVal = [''.join(c for c in s if c not in string.punctuation) for s in returnVal]\n",
    "    return list(filter(None, returnVal))\n",
    "\n",
    "# df[\"answer\"] = df[\"answer\"].apply(preprocess)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d695a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I currently do not have access to specific financial data for 3M for the year end FY2018, including the net PP&E (Property, Plant, and Equipment). To obtain this information, please refer to 3M's official financial statements for FY2018, which can typically be found in their annual report or on their investor relations website.\n"
     ]
    }
   ],
   "source": [
    "print(custom_completion(df['question'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7acf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI client, default GPT4\n",
    "default_client = OpenAI()\n",
    "custom_client = OpenAI(api_key=\"NONE\", base_url=\"https://finsearch-l35slsdlnq-uc.a.run.app\")\n",
    "def gpt_wrap_message(client: OpenAI, query: str):\n",
    "    return client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        ).choices[0].message.content\n",
    "\n",
    "def customgpt_wrap_message(client: OpenAI, query: str):\n",
    "    return client.chat.completions.create(\n",
    "        model = \"gpt-4-turbo\",\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "        ).choices[0].content\n",
    "\n",
    "\n",
    "#Check the progress meter for each of our df.apply() methods\n",
    "tqdm.pandas()\n",
    "\n",
    "#Fix argument 1 with our OpenAI clients\n",
    "default_completion = partial(gpt_wrap_message, default_client)\n",
    "custom_completion = partial(customgpt_wrap_message, custom_client)\n",
    "\n",
    "#df['gpt_answers'] = df['question'].progress_apply(default_completion)\n",
    "#df['custom_answers'] = df['question'].progress_apply(custom_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f004b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./financebench_answers.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a5be6",
   "metadata": {},
   "source": [
    "### Start Here if data is loaded from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b909f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.read_pickle('./financebench_answers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d2878f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [20:14<00:00,  8.10s/it]\n"
     ]
    }
   ],
   "source": [
    "custom_results = []\n",
    "for i in tqdm(range(len(new_df))):\n",
    "    custom_results.append(custom_completion(df['question'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3966293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = new_df.assign(custom_answers=custom_results)\n",
    "new_df2.to_pickle(\"./financebench_final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cf52310",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_df = pd.read_pickle('./financebench_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ecb2022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The FY2018 capital expenditure amount for 3M in USD millions was 1,550 million. This figure is derived from the snippet stating that 3M reported a capital expenditure of 1.55 billion in the previous year. Since 1 billion equals 1,000 million, the conversion from 1.55 billion to million is 1,550 million.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_df['custom_answers'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf54439",
   "metadata": {},
   "source": [
    "### Running Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b538347f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'answer', 'gpt_answers', 'custom_answers'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_df = pd.read_pickle('./financebench_df.pkl')\n",
    "third_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a60aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_metric import PyRouge\n",
    "\n",
    "rouge = PerlRouge(rouge_n_max=3, rouge_l=True, rouge_w=True,\n",
    "    rouge_w_weight=1.2, rouge_s=True, rouge_su=True, skip_gap=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efc9993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_answers = list(third_df['answer'].to_list())\n",
    "gpt_answers = list(map(lambda x: [x], third_df['gpt_answers'].to_list()))\n",
    "custom_answers = list(map(lambda x: [x], third_df['custom_answers'].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "569e9c95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                             $1577.00\n",
       "1                                                $8.70\n",
       "2    No, the company is managing its CAPEX and Fixe...\n",
       "3    Operating Margin for 3M in FY2022 has decrease...\n",
       "4     The consumer segment shrunk by 0.9% organically.\n",
       "Name: answer, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_df['answer'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91acd201",
   "metadata": {},
   "source": [
    "#### GPT-4 Turbo Base vs. Our RAG-enhanced API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7717b1b",
   "metadata": {},
   "source": [
    "Our new RAG engine does better on every ROUGE metric, an automatic package for evaluation of summaries. Alternatively, we can use GPT-4 to evaluate our answer outputs via OpenAI Function Calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "274b0964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.04483,\n",
       "  'r_conf_int': (0.0364, 0.05399),\n",
       "  'p': 0.38542,\n",
       "  'p_conf_int': (0.34145, 0.42995),\n",
       "  'f': 0.07402,\n",
       "  'f_conf_int': (0.06113, 0.0874)},\n",
       " 'rouge-2': {'r': 0.01419,\n",
       "  'r_conf_int': (0.00985, 0.01939),\n",
       "  'p': 0.10653,\n",
       "  'p_conf_int': (0.08209, 0.13313),\n",
       "  'f': 0.02325,\n",
       "  'f_conf_int': (0.01657, 0.03074)},\n",
       " 'rouge-3': {'r': 0.00662,\n",
       "  'r_conf_int': (0.00384, 0.01003),\n",
       "  'p': 0.0428,\n",
       "  'p_conf_int': (0.0289, 0.05753),\n",
       "  'f': 0.01067,\n",
       "  'f_conf_int': (0.00652, 0.01554)},\n",
       " 'rouge-l': {'r': 0.03621,\n",
       "  'r_conf_int': (0.02943, 0.04415),\n",
       "  'p': 0.33889,\n",
       "  'p_conf_int': (0.29708, 0.38082),\n",
       "  'f': 0.06013,\n",
       "  'f_conf_int': (0.05014, 0.07142)},\n",
       " 'rouge-w-1.2': {'r': 0.01264,\n",
       "  'r_conf_int': (0.01013, 0.01575),\n",
       "  'p': 0.27893,\n",
       "  'p_conf_int': (0.24479, 0.31593),\n",
       "  'f': 0.02308,\n",
       "  'f_conf_int': (0.01889, 0.0282)},\n",
       " 'rouge-s4': {'r': 0.01055,\n",
       "  'r_conf_int': (0.00715, 0.01474),\n",
       "  'p': 0.08543,\n",
       "  'p_conf_int': (0.06587, 0.10757),\n",
       "  'f': 0.01727,\n",
       "  'f_conf_int': (0.01216, 0.02324)},\n",
       " 'rouge-su4': {'r': 0.01614,\n",
       "  'r_conf_int': (0.01198, 0.02115),\n",
       "  'p': 0.17004,\n",
       "  'p_conf_int': (0.14326, 0.1997),\n",
       "  'f': 0.02665,\n",
       "  'f_conf_int': (0.02032, 0.03367)}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Real answers are in the correct format, so fix GPT answers and Custom Answers\n",
    "\n",
    "rouge.evaluate(real_answers, gpt_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "667bda9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.07275,\n",
       "  'r_conf_int': (0.05778, 0.09002),\n",
       "  'p': 0.35806,\n",
       "  'p_conf_int': (0.31333, 0.40407),\n",
       "  'f': 0.1044,\n",
       "  'f_conf_int': (0.08607, 0.12384)},\n",
       " 'rouge-2': {'r': 0.02727,\n",
       "  'r_conf_int': (0.01967, 0.0359),\n",
       "  'p': 0.12032,\n",
       "  'p_conf_int': (0.09326, 0.1489),\n",
       "  'f': 0.03957,\n",
       "  'f_conf_int': (0.02974, 0.05082)},\n",
       " 'rouge-3': {'r': 0.01417,\n",
       "  'r_conf_int': (0.00891, 0.02009),\n",
       "  'p': 0.06365,\n",
       "  'p_conf_int': (0.04297, 0.08572),\n",
       "  'f': 0.02062,\n",
       "  'f_conf_int': (0.0133, 0.02908)},\n",
       " 'rouge-l': {'r': 0.05916,\n",
       "  'r_conf_int': (0.0477, 0.07246),\n",
       "  'p': 0.31299,\n",
       "  'p_conf_int': (0.27379, 0.35562),\n",
       "  'f': 0.08571,\n",
       "  'f_conf_int': (0.07148, 0.10173)},\n",
       " 'rouge-w-1.2': {'r': 0.02309,\n",
       "  'r_conf_int': (0.01809, 0.02915),\n",
       "  'p': 0.26555,\n",
       "  'p_conf_int': (0.23032, 0.30412),\n",
       "  'f': 0.03773,\n",
       "  'f_conf_int': (0.03069, 0.04601)},\n",
       " 'rouge-s4': {'r': 0.01931,\n",
       "  'r_conf_int': (0.01385, 0.02555),\n",
       "  'p': 0.09398,\n",
       "  'p_conf_int': (0.07114, 0.11701),\n",
       "  'f': 0.02831,\n",
       "  'f_conf_int': (0.02085, 0.03733)},\n",
       " 'rouge-su4': {'r': 0.02822,\n",
       "  'r_conf_int': (0.02131, 0.036),\n",
       "  'p': 0.16262,\n",
       "  'p_conf_int': (0.13687, 0.19066),\n",
       "  'f': 0.04095,\n",
       "  'f_conf_int': (0.03204, 0.0509)}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.evaluate(real_answers, custom_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c70ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
